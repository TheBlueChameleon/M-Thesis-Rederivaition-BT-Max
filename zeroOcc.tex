\documentclass[
	english,
	a4paper,
	fontsize=10pt,
	parskip=half,
	titlepage=true,
	DIV=12,
	final
]{scrreprt}


%==============================================================================%
% PACKAGES
%
% Standard text formatting
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{ragged2e}

\usepackage{csquotes}
\usepackage{xspace}

\usepackage{placeins}	% FloatBarrier.
\usepackage{url}
\usepackage[bf, format=plain]{caption}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

% gfx
\usepackage{wrapfig}

% tables
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{color, colortbl}

% math
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\let\olddiv\div
\usepackage[arrowdel]{physics}
\usepackage{mathtools}

% indexes, links, page format
\usepackage{scrlayer-scrpage}

% misc
\usepackage[super]{nth}
\usepackage[
	output-decimal-marker={.},
	input-symbols = {()},  			% do not treat "(" and ")" in any special way
	group-digits  = true  			% guess what.
]{siunitx}
\usepackage{minted}

%==============================================================================%
% GLOBAL MACROS
%

% Document properties
\newcommand{\myName}{Stefan Hartinger\xspace}
\newcommand{\myTitle}{Master Thesis Notes: Deriving a Zero Occupancy Formula\xspace}

\addtokomafont{labelinglabel}{\sffamily}

% Text abbreviations
\newcommand*{\ie}{i.\,e.\xspace}
\newcommand*{\eg}{e.\,g.\xspace}

% Misc Symbols
\newcommand*{\thus}{\ensuremath{\rightarrow}\xspace}
\newcommand*{\Thus}{\ensuremath{\Rightarrow}\xspace}

% Tables
\newcommand*{\tabcrlf}{\\ \hline}			% actually still allows for optional argument

% Math
\newcommand*{\numberthis}{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand*{\smallfrac}  [2]{\ensuremath{{}^        {#1} \!/_        {#2}}}
\newcommand*{\smallfracrm}[2]{\ensuremath{{}^{\mathrm{#1}}\!/_{\mathrm{#2}}}}

\newcommand*{\transp}{\ensuremath{^\intercal}}

\newcommand*{\iunit}{\ensuremath{\mathrm{i}}}

\newcommand*{\setNaturals} {\ensuremath{\mathbb{N}}}
\newcommand*{\setIntegers} {\ensuremath{\mathbb{Z}}}
\newcommand*{\setReals}    {\ensuremath{\mathbb{R}}}
\newcommand*{\setRationals}{\ensuremath{\mathbb{Q}}}
\newcommand*{\setComplex}  {\ensuremath{\mathbb{C}}}

\newcommand*{\Lag}{\ensuremath{\mathcal{L}}\xspace}
\newcommand*{\Ham}{\ensuremath{\mathcal{H}}\xspace}

%\newcommand*{\Poisson}[2]{\ensuremath{\left\{ {#1}, {#2} \right\}}}
% physics has \pb which is poisson bracket
% also use alias acom: anticommutator, which is exactly the same.

\newcommand*{\equalCond}{  \mathop{=}\limits^!  }

\DeclareMathOperator{\arsinh}{arsinh}
\DeclareMathOperator{\diag}{diag}

%==============================================================================%
% GLOBAL PARAMTERS
%

\title{\myTitle}
\author{\myName}
\date{\today}

% header, footer
\clearpairofpagestyles
	\cfoot
		[\pagemark]
		{\pagemark}
	\ohead
		[\myTitle, \myName]
		{\myTitle, \myName}
\pagestyle{scrheadings}

%==============================================================================%
% THE REAL STUFF
%	
\begin{document}
\tableofcontents
\newpage

\chapter{Treatment of Incoming Bunched Zero-Occupancy Scenarios}
\section{Assumptions, Terminology}
For starters, we will assume that only $m_K = 0$. This shall be denoted as \emph{single zero occupancy} or \emph{SZO}.

From there on, the \emph{bunched zero occupancy} (\emph{BZO}) can be treated:
\begin{align}
	\exists b^{*} : \forall j > b^{*} : m_j = 0 \\
	\qquad \forall j \leq b^* : m_j > 0
\end{align}
This means, the \emph{incoming modes} $j = 1 \ldots b^{*}$ are occupied at least once while all higher modes are not occupied. The case $b^* = K$ corresponds to all modes occupied.

In both, SZO and BZO, we will further assume that the outgoing modes are still all occupied:
\begin{align}
	\forall j : n_j > 0
\end{align}

So, SZO translates to $b^* = K - 1$.

From there on, the generic case follows:
\begin{itemize}
\item The scenario is assumed to be symmetric in $m, n$ -- verify!
\item non-bunched configurations can be obtained by re-ordering coordinates -- verify!
\end{itemize}

\subsection{Notes on L'Hopital}
\begin{itemize}
\item It should be possible to obtain BZO solutions from SZO. Regard only one degree of freedom, treat the other ZO variables as fixed parameters.
\item After obtaining a const factor pertaining the terms depending on the SZO-zero, proceed with the next DoF.
\end{itemize}


\section{Starting Point}
Statement:
\begin{align}
	A_F(\vec{m}, \vec{n})
&=
	\eval{\qty(
			\prod_{j}
			\frac
				{1}
				{\sqrt{m_j! \; n_j!}}
			\pdv[m_j]{x_j}
			\pdv[n_j]{y_j}
		) \exp(\vec{x}\transp \, \mathbb{U} \, \vec{y})
	}_{\vec{x} = \vec{y} = \vec{0}}
\label{eqn:BSA_raw}
\end{align}

Notes:
\begin{itemize}
\item was given
\end{itemize}

Split into BZO form:
\begin{align}
	A_F(\vec{m}, \vec{n})
&=
	\eval{
		\qty(
			\prod_{j=1}^{b^*}
			\frac
				{1}
				{\sqrt{m_j! \; n_j!}}
			\pdv[m_j]{x_j}
			\pdv[n_j]{y_j}
		)
		\qty(
			\prod_{j=b^* + 1}^{K}
			\frac
				{1}
				{\sqrt{n_j!}}
			\pdv[n_j]{y_j}
		)
		\exp(\vec{x} \, \mathbb{U} \, \vec{y})
	}_{\vec{x} = \vec{y} = \vec{0}}
\label{eqn:BSA_raw_BZO}
\end{align}

Holds because:
\begin{itemize}
\item $0! = 1$
\item $\pdv[0]{z} = 1$
\end{itemize}

\section{BSA in integral form}
Equation:
\begin{align}
	A_F(\vec{m}, \vec{n})
&=
	\qty(
		\prod_{j=1}^{b^*}
			\frac
				{\sqrt{m_j! \; n_j!}}
				{-4\pi^{2}}
			\oint_{\gamma}
				\frac
					{\dd{x_j} \dd{y_j}}
					{x_j^{m_j+1}  y_j^{n_j+1}}
	)
	\qty(
		\prod_{j=b^* + 1}^{K}
			\frac
				{\sqrt{n_j !}}
				{2\pi\iunit}
			\oint_{\gamma}
				\frac
					{\dd{y_j}}
					{y_j^{n_j + 1}}
	)
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y}) \\
&=
	\qty(
		\frac{1}{2\pi\iunit}
	)^{K + b^*}
		\prod_{j=1}^{b^*}
			\sqrt{m_j! \; n_j!}
			\oint_{\gamma}
				\frac
					{\dd{x_j} \dd{y_j}}
					{x_j^{m_j+1}  y_j^{n_j+1}}
		\prod_{j=b^* + 1}^{K}
			\sqrt{n_j !}
			\oint_{\gamma}
				\frac
					{\dd{y_j}}
					{y_j^{n_j + 1}}
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y}) \\
&=
	\qty(
		\frac{1}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{m_j! \; n_k!}
		\oint_{\gamma}
			\frac
				{\dd{x_j} \dd{y_k}}
				{x_j^{m_j+1}  y_k^{n_k+1}}
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y})
	\label{eqn:BSA_Int_BZO}
\end{align}

\section{Change of Variables}
Using polar coordinates:
\begin{align}
	\begin{cases}
	x_j &= \sqrt{m_j} \exp( \iunit \theta_j) \\
	y_j &= \sqrt{n_j} \exp(-\iunit \chi  _j)
	\end{cases}
	\label{eqn:DefXY}
\end{align}

in eqn. (\ref{eqn:BSA_Int_BZO}) gives:
\begin{multline}
	A_F(\vec{m}, \vec{n})
=
	\qty(
		\frac{1}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{m_j! \; n_k!}
		\oint_{\gamma}
			\frac
				{ \sqrt{{\color{blue}-}m_j} \; \sqrt{{\color{blue}-}n_k} \; \dd{\theta_j} \dd{\chi_k}}
				{\sqrt{m_j}^{m_j+1}  \sqrt{n_j}^{n_k+1}}
			\exp( \Big. \iunit(\theta_j - \chi_k))
\\
	\exp(
		\Big.
		-\iunit (m_j + 1) \theta_j
		+\iunit (n_k + 1) \chi  _k
	)
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y})
\end{multline}
(the negative arguments in the roots $\sqrt{-m_j}, \sqrt{-n_k}$ ensure correct counting of imaginary units $\iunit$, which, in turn, stem from substituting 
$(\vec{x}, \vec{y}) \to (\vec{\theta}, \vec{\chi})$:
\begin{align}
	\dd{x_j}
&=
	\dv{x_j}{\theta_j} \dd{\theta_j}
=
	\iunit \, \sqrt{m_j} \, \exp(\iunit \theta_j) \dd{\theta_j}
=
	\sqrt{-m_j} \, \exp(\iunit \theta_j) \dd{\theta_j}
\end{align}
and likewise for $y_k \to \chi_k$.

With this, get:
\begin{multline}
	A_F(\vec{m}, \vec{n})
=
	\qty(
		\frac{{\color{blue}\iunit}}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{m_j! \; n_k!}
		\oint_{\gamma}
			\frac
				{\dd{\theta_j} \dd{\chi_k}}
				{\sqrt{m_j}^{m_j}  \sqrt{n_j}^{n_k}}
\\
	\exp(
		\Big.
		-\iunit m_j \theta_j
		+\iunit n_k \chi  _k
	)
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y})
\end{multline}
\begin{multline}
	\qquad\qquad
=
	\qty(
		\frac{\iunit}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{\frac
			{m_j! \; n_k!}
			{m_j^{m_j}  n_j^{n_k}}
		}
		\oint_{\gamma}
			\dd{\theta_j} \dd{\chi_k}
	\exp(
		\Big.
		-\iunit m_j \theta_j
		+\iunit n_k \chi  _k
	)
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y})
\end{multline}

using
\begin{align}
	C
&=
	\qty(
		\frac{\iunit}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{\frac
			{m_j! \; n_k!}
			{m_j^{m_j}  n_j^{n_k}}
		}
\end{align}
({\color{red}keep in mind that this definition of $C$ differs from the fully-occupied scenario!})
gives
\begin{align}
	A_F(\vec{m}, \vec{n})
&=
	C
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\oint_{\gamma}
			\dd{\theta_j} \dd{\chi_k}
	\exp(
		\Big.
		-\iunit m_j \theta_j
		+\iunit n_k \chi  _k
	)
	\exp( \Big. \vec{x} \, \mathbb{U} \, \vec{y}) \\
&=
	C
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\oint_{\gamma}
			\dd{\theta_j} \dd{\chi_k}
	\exp(
		\Big.
		-\iunit m_j \theta_j
		+\iunit n_k \chi  _k
	)
	\exp(
		\sum_{k,l=1}^{K}
		\sqrt{m_k, n_l} \;
		u_{k,l}
		\exp(\Big.
			\iunit(\theta_k - \chi_l)
		)
	)
	\label{eqn:BSA_Int_BZO_Polar}
\end{align}
Note
\begin{itemize}
\item although there are zeros in $\vec{m}$, this could still be written in terms of a dot product
	$\vec{n} \cdot \vec{\chi} - \vec{m} \cdot \vec{\theta}$
	, as contributions from $j > b^*$ simply vanish.
\item because of this, no special treatment of the matrix multiplication $\vec{x} \, \mathbb{U} \, \vec{y}$ is needed.
\end{itemize}

\section{Integrating out the $\theta_1$ DoF}
split eqn. (\ref{eqn:BSA_Int_BZO_Polar}) into $\theta_1$ dependent terms and rest. Use temporary variables:
\begin{align}
	\vec{\alpha} &= \vec{\theta} - (\theta_1, \ldots, \theta_1)\transp
	&
	\vec{\theta} &= \vec{\alpha} + (\theta_1, \ldots, \theta_1)\transp
\\
	\vec{\beta } &= \vec{\chi  } - (\theta_1, \ldots, \theta_1)\transp
	&
	\vec{\chi  } &= \vec{\beta } + (\theta_1, \ldots, \theta_1)\transp
\end{align}
and get
\begin{multline}
	A_F(\vec{m}, \vec{n})
=
	C
	\prod_{k=1}^{K}
	\prod_{{\color{blue} j=2}}^{b^*}
		\oint_{\gamma}
			\dd{\alpha_j} \dd{\beta_k}
		\int_{0}^{2\pi} {\color{blue} \dd{\theta_1}}
			\exp(
				\Big.
				\iunit (
				n_k \beta _k   -
				m_j \alpha_j
			))
\\
	\exp(
		\iunit \qty(
			\sum_{p=1}^{K}   n_p   -
			\sum_{q=1}^{b^*} m_q
		)
		{\color{blue} \theta_1}
	)
	\exp(
		\sum_{p,q=1}^{K}
		\sqrt{m_p, n_q} \;
		u_{p,q}
		\exp(\Big.
			\iunit(\alpha_p - \beta_q)
		)
	)
\end{multline}

As in Max' paper, get a Kronecker Delta from the $\theta_1$ exponential:
\begin{multline}	
	A_F(\vec{m}, \vec{n})
=
	2\pi \delta_{M,N} C
	\prod_{k=1}^{K}
	\prod_{j=2}^{b^*}
		\oint_{\gamma}
			\dd{\alpha_j} \dd{\beta_k}
\\
	\exp(
		\Big.
		\iunit(
		n_k \beta _k   -
		m_j \alpha_j
	))
	\exp(
		\sum_{p,q=1}^{K}
		\sqrt{m_p, n_q} \;
		u_{p,q}
		\exp(\Big.
			\iunit(\alpha_p - \beta_q)
		)
	)
\end{multline}
and resubstitute $(\vec{\alpha}, \vec{\beta}) \to (\vec{\theta}, \vec{\chi})$:
\begin{multline}	
	A_F(\vec{m}, \vec{n})
=
	2\pi \delta_{M,N} C
	\prod_{k=1}^{K}
	\prod_{j=2}^{b^*}
		\oint_{\gamma}
			\dd{\theta_j} \dd{\chi_k}
\\
	\exp(
		\Big.
		\iunit(
		n_k \chi  _k   -
		m_j \theta_j
	))
	\exp(
		\sum_{p,q=1}^{K}
		\sqrt{m_p, n_q} \;
		u_{p,q}
		\exp(\Big.
			\iunit(\theta_p - \chi_q)
		)
	)
\end{multline}
with arbitrary def: $\theta_1 = 0$

\section{Applying SPA}
\subsection{Definitions}
Using
\begin{align}
	\lambda
&=
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		m_j \, n_k
\\
	f(
		\underbrace{ \vec{\theta}, \vec{\chi} }_{\vec{z}}
	)
&=
	\iunit
	\lambda^{-1}
	\qty[
		\qty(
			\sum_{j=1}^{b^*}
				m_j \theta_j   -
			\sum_{k=1}^{K}
				n_k \chi  _k
		)
	-
		\qty(
			\sum_{s,t=1}^{K}
			\sqrt{m_s, n_t} \;
			u_{s,t}
			\exp(\Big.
				\iunit(\theta_s - \chi_t)
			)
		)
	]
\\
	\oint_{\gamma} \dd[n]{\vec{z}}
		\exp[-\lambda f(\vec{z})]
&=
	\qty( \frac
		{2\pi}
		{\lambda}
	)^{\frac{n}{2}}
	\sum_{r}
		\frac
		{\exp(-\lambda f(\vec{z}_r))}
		{\sqrt{\det S_r}}
\label{eqn:def_SPA}
\end{align}
where $\vec{z}_r$ are the local extrema of $f$: $\eval{\dv{\vec{z}}f}_{\vec{z} = \vec{z}_r} = 0$\\
and $S_r$ is the Hessian of $f$ evaluated in $\vec{z}_r$\\
{\color{red} note that $\lambda$ differs from the fully occupied form.}

\subsection{Saddle Points}
\label{sec:saddles}
Require:
\begin{align}
	\pdv{f}{\theta_p} &\equalCond 0
&
	\pdv{f}{\chi  _q} &\equalCond 0 
\end{align}
with $p \in \{2, \ldots, b^*\}$ and $q \in \{1, \ldots, K\}$

Find:
\begin{gather}
	\pdv{f}{\theta_p}
=
	\iunit \lambda^{-1}
	\qty[
		m_p
		-
		\sum_{l=1}^{K}
			\sqrt{m_p n_l} \; u_{p,l} \; \exp[ \Big. \iunit(\theta_p - \chi_l)]
	]
	\label{eqn:Jacobiantheta}
\equalCond
	0 \\
\Thus
	m_p
\equalCond
	\sum_{l=1}^{K}
		\sqrt{m_p n_l} \; u_{p,l} \; \exp[ \Big. \iunit(\theta_p - \chi_l) ] \\
\Thus
	\sqrt{m_p} \exp(-\iunit \theta_p)
\equalCond
	\sum_{l=1}^{K} \sqrt{n_l} \; u_{p,l} \; \exp(-\iunit\chi_l)
	\label{eqn:FourierLinkForward}
\end{gather}
with $p \in \{2, \ldots, K\}$ where $\theta_1 = 0$. Implicitly also holds for $p=1$ {\color{red}(Does it?)}, but the derivatives only start at $p=2$.

Likewise:
\begin{gather}
	\pdv{f}{\chi_q}
=
	\iunit\lambda^{-1}
	\qty[
		- n_q
		+
		\sum_{k=1}^{K}
			\sqrt{m_k n_q} \; u_{k,q} \; \exp[ \Big. \iunit(\theta_k - \chi_q) ]
	]
	\label{eqn:JacobianChi}
\equalCond
	0 \\
\Thus
	\sqrt{n_q} \exp(+\iunit \chi_q)
\equalCond
	\sum_{k=1}^{K}
	\sqrt{m_k} \; u_{k,q} \; \exp(+\iunit\theta_k)
	\label{eqn:FourierLinkBackward}
\end{gather}
with $q \in \{1, \ldots, K\}$ where again $\theta_1 = 0$

Compactly:
\begin{align}
	\vec{x}^{*} &= \mathbb{U} \vec{y}
&
	\vec{y}^{*} &= \mathbb{U}\transp \vec{x}
	\label{eqn:MatrixCondition}
\end{align}

\subsection{Main Results up to here}
\begin{itemize}
\item The phase relation still holds for BZO scenarios!
\item normalization constants need to be adjusted:
	\begin{itemize}
	\item $C =
	\qty(
		\frac{\iunit}{2\pi\iunit}
	)^{K + b^*}
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		\sqrt{\frac
			{m_j! \; n_k!}
			{m_j^{m_j}  n_j^{n_k}}
		}$
	\item $\lambda =
	\prod_{k=1}^{K}
	\prod_{j=1}^{b^*}
		m_j \, n_k$
	\end{itemize}
\item The formulae up to here should not be applied to ZO modes, albeit behaviour for such $m_p$
	implies that they are even valid there.
\item strictly speaking, the matrix sum over $k$ should be adjusted such that no $\theta_k$ with
	$k > b^*$ are referenced. However, all instances where this happens are weighted with a
	$\sqrt{m_k} = 0$.
\end{itemize}

\section{Hessian}
Recall: We start from
\begin{align}
	S_r
=
	\eval{
		\pdv{f(\vec{z})}%
			{z_\alpha}{z_\beta}
	}_{\vec{z} = \vec{z}_r}
\end{align}
but only true DoFs are relevant. Hence, regard $m_j, n_j$ and $\theta_1$ as const. \\
\Thus $(K + b^* - 1)^{2}$ derivatives wrt. $\theta_2, \ldots \theta_{b^*}, \chi_1, \ldots, \chi_K$

Compactly: Use $\vec{z}_j = \vec{\theta} \oplus \vec{\chi}$, \ie the entire Fourier pair. Re-use eqns (\ref{eqn:Jacobiantheta}) and (\ref{eqn:JacobianChi}) from \ref{sec:saddles} by introducing (remembering the constraint $\theta_1 = 0$):

\begin{align}
	\mathbb{J} = \qty( \grad_{\vec{z}_j} f )
\end{align}
\begin{align}
	J_{\theta, p} 
&= 
	\pdv{f}{\theta_p}
=
	\iunit \lambda^{-1}
	\qty[
		+m_p
		-
		\sum_{l=1}^{K}
			\sqrt{m_p n_l} \; u_{p,l} \; \exp[\Big. \iunit(\theta_p - \chi_l)]
	]
\qfor{} p = 2, \ldots, b^*
\\
	J_{\chi, q} 
&= 
	\pdv{f}{\chi_q}
=
	\iunit \lambda^{-1}
	\qty[
		-n_q
		+
		\sum_{k=1}^{K}
			\sqrt{m_k n_q} \; u_{k,q} \; \exp[\Big. \iunit(\theta_k - \chi_q)]
	]
\qfor{} q = 1, \ldots, K
\end{align}
Understand $\mathbb{J}$ as a \emph{column vector}. In spite of it having two indices here, there is only one dimension. $\theta, \chi$ refer to subblocks in the vector rather than degrees of freedom.

Total dimension of $\mathbb{J}$ is $(K + b^* - 1) \times 1$ due to constraint $\theta_1 = 0$

Get Hessian matrix elements:
\begin{align}
	\qty( S_j )
&=
	\begin{pmatrix}
		\pdv{J_{\theta}}{\vec{\theta}} &
		\pdv{J_{\theta}}{\vec{\chi  }} 
		\\
		\pdv{J_{\chi  }}{\vec{\theta}} &
		\pdv{J_{\chi  }}{\vec{\chi  }} 
	\end{pmatrix}
\end{align}
\begin{align}
	\pdv{J_{\theta, p}}{\theta_{\alpha}}
&=
	+
	\lambda^{-1}
	\delta_{p,\alpha}
	\sum_{l=1}^{K}
		\sqrt{m_p n_l} \; u_{p,l} \; \exp[\Big. \iunit(\theta_p - \chi_l)]
&\text{for } \alpha = 2, \ldots, b^*
\\
	\pdv{J_{\theta, p}}{\chi_{\alpha}}
&=
	-
	\lambda^{-1}
	\sqrt{m_p n_\alpha} \; u_{p,\alpha} \; \exp[\Big. \iunit(\theta_p - \chi_\alpha)]
&\text{for } \alpha = 1, \ldots, K
\\
	\pdv{J_{\chi, q}}{\theta_{\alpha}}
&=
	-
	\lambda^{-1}
	\sqrt{m_\alpha n_q} \; u_{\alpha,q} \; \exp[\Big. \iunit(\theta_\alpha - \chi_q)]
&\text{for } \alpha = 2, \ldots, b^*
\\
	\pdv{J_{\chi, q}}{\chi_{\alpha}}
&=
	+
	\lambda^{-1}
	\delta_{q,\alpha}
	\sum_{k=1}^{K}
		\sqrt{m_k n_q} \; u_{k,q} \; \exp[\Big. \iunit(\theta_k - \chi_q)]
&\text{for } \alpha = 1, \ldots, K
\end{align}
Dimensions:
\begin{align}
	\dim S_j
&=
	\begin{pmatrix}
		(b^* - 1) \times (b^* - 1)	& (b^* - 1) \times K \\
		K \times (b^* - 1)			& K \times K
	\end{pmatrix}
=
	(K + b^* - 1) \times (K + b^* - 1)
\end{align}

The Kronecker Delta is due to the fact that the derived-for variable is present only once at the stage of Jacobian $\mathbb{J}$.

Using the eqns (\ref{eqn:FourierLinkForward}) and (\ref{eqn:FourierLinkBackward}), we can further collapse the diagonal elements:
\begin{align}
	\pdv{J_{\theta, p}}{\theta_{\alpha}}
&=
	\lambda^{-1}
	\delta_{p,\alpha}
	m_p
&
	p \in \{2, \ldots, b^*\}
\\
	\pdv{J_{\chi, q}}{\chi_{\alpha}}
&=
	\lambda^{-1}
	\delta_{q,\alpha}
	n_q
&
	q \in \{1, \ldots, K\}
\end{align}

Thus:
\begin{align}
	(S_j)
&=
	\lambda^{-1}
	\diag(\vec{m}', \vec{n})
	+
	\begin{pmatrix}
		\mathds{O}_{b^*-1} & 
		\pdv{J_{\theta, p}}{\chi_{\alpha}}
		\\
		\pdv{J_{\chi, q}}{\theta_{\alpha}} &
		\mathds{O}_{K}
	\end{pmatrix}
=
	\lambda^{-1}
	\begin{pmatrix}
		\diag(\vec{m}') & F 			\\
		F\transp & \diag(\vec{n})
	\end{pmatrix}
\end{align}
where
\begin{align}
	F
&:=
	\lambda \qty( \pdv{J_{\theta}}{\vec{\chi}} ) 
	= \lambda \qty( \pdv{J_{\chi}}{\vec{\theta}} )\transp
	= \qty( -\sqrt{m_p n_q} \; u_{p,q} \; \exp[\Big. \iunit(\theta_p - \chi_q)] )_{
		\substack{p = 2, \ldots, b^* \\ q = 1, \ldots, K}
	}	
\end{align}
where $\mathds{O}_{D}$ is a $D \times D$ null-matrix, and $\vec{m}' = (m_2, \ldots, m_{b^*})\transp$

The implied symmetry of the off-diagonal blocks is guaranteed by this being a Hessian matrix and can be read from the off-diagonal blocks by comparing the position of indices.

Note:
\begin{itemize}
\item $(S_j)$ is of dimension $(K + b^* - 1)^{2}$.
\item $F$ is of dimension $(b^* - 1) \times K$
\end{itemize}

\section{Determinant of the Hessian}
\subsection{Determinant-Preserving Expansion}
\subsubsection{Theorem: Determinant-perserving expansion by unity block}
Let there be a matrix $M \in \setReals^{D \times D}$, as well as a matrix $M'$:
\begin{align}
	M'
&=
	\begin{pmatrix}
		\mathds{1}_{E} & \mathds{O}_{E \times D} \\
		\mathds{O}_{D \times E} & M
	\end{pmatrix}
\end{align}
where $\mathds{1}_{E}$ is the unit matrix of dimension $E$ and $\mathds{O}_{E \times D}$ is a null matrix of dimension $E \times D$.

Then,
\begin{equation}
	\forall E \in \setNaturals : \det M = \det M'
\end{equation}

\textbf{Proof:}\\
Regard the Matrix $M^{(n)}$:
\begin{align}
	M^{(n)}
&=
	\begin{pmatrix}
		\mathds{1}_{n} & \mathds{O}_{n \times D} \\
		\mathds{O}_{D \times n} & M
	\end{pmatrix}
\end{align}
\ie $M^{(E)} = M'$. The determinant of $M^{(1)}$ can be easily found from the Laplace expansion:

For an $n \times n$ matrix $B = (b_{i,j})$, and an arbitrary, fixed $r = 1, \ldots, n$, the determinant is given by:
\begin{align}
	\det B
&=
	\sum_{j=1}^{n}
		b_{rj} C_{rj}
\end{align}
where $C_{ij}$ is the cofactor to the $i^{\text{th}}$ row and $j^{\text{th}}$ column, \ie the determinant of the submatrix with the indexed row and column removed, times $(-1)^{i+j}$.

So for the given $M^{(1)}$, and choosing $r = 1$, the determinant reads:
\begin{align}
	\det M^{(1)}
&=
	1 \det M^{(0)} + 0 \\
&=
	\det M
\end{align}

Further, it can easily be seen that
\begin{align}
	\det M^{(n)} = \det M^{(n-1)} = \det M
\end{align}
and from this follows the claim.
\begin{flushright}
	\emph{q.e.d.}
\end{flushright}

\subsubsection{Theorem: Determinant-perserving expansion by unity infix}
Let $M$ be as above, with the blocks:
\begin{align}
	M
&=
	\begin{pmatrix}
		A & B \\ C & D
	\end{pmatrix}
\end{align}
and
\begin{align}
	M'
&=
	\begin{pmatrix}
		A & \mathds{O} & B \\
		\mathds{O} & \mathds{1}_{E} & \mathds{O} \\
		C & \mathds{O} & D
	\end{pmatrix}
\end{align}

Then
\[ \forall E \in \setNaturals : \det M = \det M' \]

\textbf{Proof:}\\
From the same arguments as in the last theorem, but choosing $r$ such that it denotes the row above $D$.
\begin{flushright}
	\emph{q.e.d.}
\end{flushright}


\subsection{Definitions: $2K \times 2K$ form}
Let $\tilde{S}$ be the expansion of $S$ to dimension $2K \times 2K$ of the same determinant:
\begin{align}
	\tilde{S}
&=
	\lambda^{-1}
	\begin{pmatrix}
		\mqty{	1 & \mathds{O}_{1 \times (b^* - 1)} \\ 
				\mathds{O}_{(b^* - 1) \times 1} & \diag(\vec{m'})} &
		\mathds{O}_{b^* \times (K - b^*)}	& 
		\mqty{\mathds{O}_{1 \times K} \\ F}
	\\
		\mathds{O}_{(K - b^*) \times b^*}  &  \mathds{1}_{K - b^*}  &  \mathds{O}_{(K - b^*) \times K}
	\\
		\mqty{\mathds{O}_{K \times 1} & F\transp} & 
		\mathds{O}_{K \times (K - b^*)} & \diag(\vec{n})
	\end{pmatrix}
\end{align}
(overview form without dimensions):
\begin{align}
	\tilde{S}
&=
	\lambda^{-1}
	\begin{pmatrix}
		1			& \mathds{O} 		& \mathds{O}		& \mathds{O} \\
		\mathds{O}	& \diag(\vec{m'})	& \mathds{O}		& F          \\
		\mathds{O}	& \mathds{O}			& \mathds{1}		& \mathds{O} \\
		\mathds{O}	& F\transp			& \mathds{O}		& \diag(\vec{n})
	\end{pmatrix}
\end{align}

where still:
\begin{align}
	F
&:=
	\lambda \qty( \pdv{J_{\theta}}{\vec{\chi}} ) 
	= \lambda \qty( \pdv{J_{\chi}}{\vec{\theta}} )\transp
	= \qty( -\sqrt{m_p n_q} \; u_{p,q} \; \exp[\Big. \iunit(\theta_p - \chi_q)] )_{
		\substack{p = 2, \ldots, b^* \\ q = 1, \ldots, K}
	}
\label{eqn:defDetOffDiagonalF}
\\
	\vec{m}'
&=
	(m_2, \ldots, m_{b^*})\transp
\end{align}

With this, implicitly using the infix theorem:
\begin{align}
	\det S
&=
	\lambda^{-K - b^* + 1}
	\underbrace{\mqty|
		1			& \mathds{O} 		& \mathds{O}		& \mathds{O} \\
		\mathds{O}	& \diag(\vec{m'})	& \mathds{O}		& F          \\
		\mathds{O}	& \mathds{O}			& \mathds{1}		& \mathds{O} \\
		\mathds{O}	& F\transp			& \mathds{O}		& \diag(\vec{n})
	|}_{= S'}
=
	\lambda^{-K - b^* + 1}
	\mqty|
		\diag(\tilde{\vec{m}})	& \tilde{F}			\\
		\tilde{F}\transp			& \diag(\vec{n})
	|
\label{eqn:detS_protoform}
\end{align}
explicit:
\begin{itemize}
\item $\tilde{\vec{m}} = (
	1,
	\underbrace{m_2, \ldots, m_{b^*}}_{b^* -1 \text{ items}},
	\underbrace{1, \ldots, 1}_{K - b^* \text{ times}}
	~)\transp$ is of dimension $K$
\item $\tilde{F} = \begin{pmatrix}
		\mathds{O}_{1 \times K} \\ 
		F \\ 
		\mathds{O}_{K - b^* \times K}
	\end{pmatrix}$
	is of dimension $K \times K$
\end{itemize}

\subsection{Alternative Form}
Statement:
\begin{align}
	\det S'
&=
	\mqty|
		\underbrace{\begin{pmatrix}
			\diag(\tilde{\vec{m}})	& \mathds{O}			\\
			\tilde{F}\transp			& \mathds{1}
		\end{pmatrix}}_{2K \times 2K}
		\cdot
		\underbrace{\begin{pmatrix}
			\mathds{1}	&	\qty(\diag(\tilde{\vec{m}}))^{-1} \tilde{F}		\\
			\mathds{O}	&	\diag(\vec{n}) - \tilde{F}\transp \qty(\diag(\tilde{\vec{m}}))^{-1}\tilde{F}
		\end{pmatrix}}_{2K \times 2K}
	|
	\label{eqn:detProto}
\end{align}
Holds because:
\begin{itemize}
\item Multiplication yields identity
\end{itemize}

\subsection{Partial Evaluation of the determinant}
Statement
\begin{align}
	\det S'
&=
	\underbrace{
		\qty( \prod_{j=1}^{K} \tilde{m}_j n_j )
	}_{= \mathcal{N} }
	\det[
		\mathds{1} -
		\tilde{F}\transp \cdot \qty( \diag(\tilde{\vec{m}}) )^{-1}
		\cdot
		\tilde{F} \cdot \qty( \diag(\tilde{\vec{n}}) )^{-1}
	]
\label{eqn:detSPrimePartial}
\end{align}
Note: $\lambda \neq \mathcal{N}$, but $\lambda = m_1 \mathcal{N}$ {\color{red} and $\lambda$ is still different from the fully occupied form}.

Explicit:
\begin{align}
	\mathcal{N}
&=
	\prod_{k=1}^{K}
	\prod_{j=2}^{b^*}
		m_j n_k
\end{align}

Holds because
\begin{itemize}
\item directly taken from rederivation.
\end{itemize}

\subsection{Reforming $\tilde{F}$}
Statement:
\begin{align}
	\tilde{F}
&=
	\diag\qty[ \sqrt{ \tilde{\vec{m}}} * \exp(+\iunit \vec{\theta}) ]
	\cdot \tilde{\mathbb{U}} \cdot
	\diag\qty[ \sqrt{        \vec{n} } * \exp(-\iunit \vec{\chi  }) ]
\end{align}
(where $*$ denotes component-wise multiplication. Likewise, $\sqrt{.}$ and $\exp(.)$ are understood to act on the components of the vectors individually.)

Where:
\begin{equation}
	\tilde{u}_{i,j} = \begin{cases}
		-u_{i,j}		&\qq*{for } 2 \leq i \leq b^* \\
		0			&\qotherwise*
	\end{cases}
\end{equation}
{\color{red} This alters from the original definition of $\tilde{\mathbb{U}}$}.

Note that this suppresses the necessity of the condition $\theta_1 = 0$. Likewise, the phases of nonoccupied modes ($i > b^*$) are ignored.


Holds because:
\begin{itemize}
\item see definition of F in eqn. (\ref{eqn:defDetOffDiagonalF})
\end{itemize}

\subsection{Reformed $\tilde{F}$ in the determinant}
Statement:
\begin{align}
	\det S'
&=
	\mathcal{N}
	\qty( \prod_{j=1}^{K} \exp(-2\iunit \chi_j) )
	\det\qty[\bigg.
		\diag\qty(\exp(\Big.2\iunit\vec{\chi}))
		-
		\tilde{\mathbb{U}}\transp
		\diag\qty(\exp(2\iunit\vec{\theta}))
		\tilde{\mathbb{U}}
	]
\end{align}
where, again, $\exp(.)$ is understood to act on the individual components of a vector.

Holds because:
\begin{itemize}
\item taken from rederivation
\item tested superficially for compatibility with new vector $\tilde{\vec{m}}$
\end{itemize}

\subsection{Complete Det of the Hessian}
Statement:
\begin{align}
	\det S
&=
	\frac{ \lambda^{-K - b^* + 2} }{ m_1 }
	\qty( \prod_{j=1}^{K} \exp(-2\iunit \chi_j) )
	\det\qty[\bigg.
		\diag\qty(\exp(\Big.2\iunit\vec{\chi}))
		-
		\tilde{\mathbb{U}}\transp
		\diag\qty(\exp(2\iunit\vec{\theta}))
		\tilde{\mathbb{U}}
	]
\label{eqn:detComplete}
\end{align}

Holds because:
\begin{itemize}
\item Phase term as found in rederivation
\item magnitude:
	\begin{itemize}
	\item Start from eqn. (\ref{eqn:detS_protoform}) : $\det S = \lambda^{-K - b^* + 1} \det S'$
	\item $
	\frac
		{\mathcal{N}}
		{\lambda^{K + b^* - 1}}
%=
%	\frac
%		{ \prod_{k=1}^{K} \prod_{j=2}^{b^*} m_j \, n_k}
%		{(\prod_{k=1}^{K} \prod_{j=1}^{b^*} m_j \, n_k)^{K + b^* - 1}}
%=
%	\frac
%		{     \mathcal{N}}
%		{(m_1 \mathcal{N})^{K + b^* - 1}}
=
	\frac
		{\lambda / m_1}
		{\lambda^{K + b^* - 1}}
=
	\frac{\lambda^{- K - b^* + 2}}{m_1}
$	
	\end{itemize}
\end{itemize}

\section{Complete Amplitude Formula}
Statement:
\begin{align}
	A_F(\vec{m}, \vec{n})
&=
	\qty(
		\frac{2\pi}{\lambda}
	)^{\frac{K + b^*}{2}}
	\sum_r
		\frac
		{\overbrace{
			\exp[-\lambda f(\vec{z}_r)]
		}^{\mathcal{E}}}
		{\sqrt{\det S_r}}
\end{align}
from SPA formula eqn. (\ref{eqn:def_SPA}) with
\begin{align}
	\mathcal{E}
&=
	\exp[ 
		\qty(- \sum_{k=2}^{K} \iunit m_k \theta_k) + 
		\qty(  \sum_{k=1}^{K} \iunit n_k \chi_k)   +
		\vec{x}\transp \, \mathbb{U} \, \vec{y}
	] \\
&=
	\exp[ 
		\qty(- \sum_{k=2}^{K} \iunit m_k \theta_k) + 
		\qty(  \sum_{k=1}^{K} \iunit n_k \chi_k)   +
		N
	]
\end{align}

\section{Specialization: 2x2}

\end{document}